# -*- coding: utf-8 -*-
"""Machine_learning_part (1) (2).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yVJjumn3y7_cKVRFP83uYbJLQr_2N_4G

# Machine Learning Part
## Step 1: using original data
"""

# imports
import pandas as pd
import numpy as np
import cv2
from scipy import ndimage as nd
import matplotlib.pyplot as plt
import os
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn import metrics
from sklearn.preprocessing import LabelEncoder
from yellowbrick.classifier import ROCAUC
import pickle
from skimage.filters import roberts, sobel, scharr, prewitt

#import image data
import random
path="brain_tumor_custom/Tumor"
img_list = list(sorted(os.listdir(path)))
train_names = random.sample(img_list, int(len(img_list)*0.8))
test_names = [x for x in img_list if x not in train_names]
test_names

dataset_of_images = pd.DataFrame()  # Initialize DataFrame to store image data

for image in sorted(os.listdir(path)):
    if image in train_names:
        print(image)
        temp_df = pd.DataFrame()  # Create a temporary DataFrame for each image
        input = cv2.imread(os.path.join(path, image))  # Use os.path.join to construct file paths

        if input is None:
            print(f"Failed to read image: {image}")
            continue  # Skip processing this image and move to the next one

        # Check all images are gray scale images and 2D
        if input.ndim == 3 and input.shape[-1] == 3:
            img = cv2.cvtColor(input, cv2.COLOR_BGR2GRAY)
        elif input.ndim == 2:
           img = input
        else:
           raise Exception("This model works only with 2D")

        # ADD DATA TO THE DATAFRAME

        # Add pixel values to the data frame
        pixel_values = img.reshape(-1)
        temp_df['Pixel_Value'] = pixel_values  # Pixel value itself as a feature
        temp_df['Image_Name'] = image  # Capture image name as we read multiple images

        # Generate Gabor features
        num = 1  # To count numbers up in order to give Gabor features a label in the data frame
        kernels = []
        for theta in range(2):  # Define number of thetas
            theta = theta / 4. * np.pi
            for sigma in (1, 3):  # Sigma with 1 and 3
                for lamda in np.arange(0, np.pi, np.pi / 4):  # Range of wavelengths
                    for gamma in (0.05, 0.5):  # Gamma values of 0.05 and 0.5
                        gabor_label = 'Gabor' + str(num)  # Label Gabor columns as Gabor1, Gabor2, etc.
                        kernel = cv2.getGaborKernel((9, 9), sigma, theta, lamda, gamma, 0, ktype=cv2.CV_32F)
                        kernels.append(kernel)
                        # Now filter the image and add values to a new column
                        fimg = cv2.filter2D(img, cv2.CV_8UC3, kernel)
                        filtered_img = fimg.reshape(-1)
                        temp_df[gabor_label] = filtered_img  # Label columns as Gabor1, Gabor2, etc.
                        print(gabor_label, ': theta=', theta, ': sigma=', sigma, ': lamda=', lamda, ': gamma=', gamma)
                        num += 1  # Increment for gabor column label

         # Add Canny edge feature
        edges = cv2.Canny(img, 100, 200)
        edges1 = edges.reshape(-1)
        temp_df['Canny Edge'] = edges1

        # Add Roberts edge feature
        edge_roberts = roberts(img)
        edge_roberts1 = edge_roberts.reshape(-1)
        temp_df['Roberts'] = edge_roberts1

        # Add Sobel edge feature
        edge_sobel = sobel(img)
        edge_sobel1 = edge_sobel.reshape(-1)
        temp_df['Sobel'] = edge_sobel1

        # Add Scharr edge feature
        edge_scharr = scharr(img)
        edge_scharr1 = edge_scharr.reshape(-1)
        temp_df['Scharr'] = edge_scharr1

        # Add Prewitt edge feature
        edge_prewitt = prewitt(img)
        edge_prewitt1 = edge_prewitt.reshape(-1)
        temp_df['Prewitt'] = edge_prewitt1

        # Add Gaussian filter with sigma=3
        gaussian_img = nd.gaussian_filter(img, sigma=3)
        gaussian_img1 = gaussian_img.reshape(-1)
        temp_df['Gaussian s3'] = gaussian_img1

        # Add Gaussian filter with sigma=7
        gaussian_img2 = nd.gaussian_filter(img, sigma=7)
        gaussian_img3 = gaussian_img2.reshape(-1)
        temp_df['Gaussian s7'] = gaussian_img3

        # Add Median filter with size=3
        median_img = nd.median_filter(img, size=3)
        median_img1 = median_img.reshape(-1)
        temp_df['Median s3'] = median_img1


        # Update dataframe for images to include details for each image in the loop
        dataset_of_images = pd.concat([dataset_of_images, temp_df], axis=0)

"""read masks"""

path_toMask="brain_tumor_custom/Mask"
mask_dataset = pd.DataFrame()
for mask in sorted(os.listdir(path_toMask)):
    m = mask.replace("_mask" , "")
    if m in train_names:
        print(mask)
        temp_df2 = pd.DataFrame()
        input_Mask = cv2.imread(os.path.join(path_toMask, mask))

        if input_Mask is None:
            print(f"Failed to read image: {mask}")
            continue  # Skip processing this image and move to the next one

        # Check all images are gray scale images and 2D
        if input_Mask.ndim == 3 and input_Mask.shape[-1] == 3:
          LabelMask = cv2.cvtColor(input_Mask, cv2.COLOR_BGR2GRAY)
        elif input_Mask.ndim == 2:
           LabelMask = input_Mask
        else:
            raise Exception("This model works only with 2D mask")

        #Add pixel values to the data frame
        labelValues = LabelMask.reshape(-1)
        temp_df2['Label_Value'] = labelValues
        temp_df2['Mask_Name'] = mask

        mask_dataset = pd.concat([mask_dataset, temp_df2], axis=0)

#concatinate both datasets.
entire_dataset = pd.concat([dataset_of_images, mask_dataset], axis=1)

entire_dataset

# Assuming 'Image_Name' and 'Mask_Name' are columns in your DataFrame 'entire_dataset'

# Extract the common part of the names (without the '_mask' suffix)
entire_dataset['Mask_Name'] = entire_dataset['Mask_Name'].str.replace('_mask', '')

# Check if the common parts of the names are equal
matches = entire_dataset['Image_Name'] == entire_dataset['Mask_Name']

# Check if all matches are True
if matches.all():
    print("All images match their corresponding masks.")
else:
    print("Some images do not match their corresponding masks.")

"""splitting data to train and validation"""

X = entire_dataset.drop(labels = ["Image_Name", "Mask_Name", "Label_Value"], axis=1)
Y = entire_dataset["Label_Value"].values
print(np.unique(Y))
Y = LabelEncoder().fit_transform(Y)
print(np.unique(Y))
##Split data into train and test
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=20)

"""Modeling
note: we tried RandomizedSearchCV and GridSearchCV but due to the huge data size we were unable to get any output and the kernal dies every time.
"""

RFmodel = RandomForestClassifier(n_estimators = 50, random_state = 42)
## Train the model on training data
RFmodel.fit(X_train, y_train)
prediction_test = RFmodel.predict(X_test)
##Check accuracy on test dataset.
print ("Accuracy = ", metrics.accuracy_score(y_test, prediction_test))

print("Classes in the image are: ", np.unique(Y))
#ROC curve for RF
roc_auc=ROCAUC(RFmodel, classes=[0, 1])  #Create object
roc_auc.fit(X_train, y_train)
roc_auc.score(X_test, y_test)
roc_auc.show()

##Save the trained model as pickle string to disk for future use
model_name = "segmentation"
pickle.dump(RFmodel, open(model_name, 'wb'))

# Define a function to extract features from an image
def extract_features(image_path):
    # Read the image
    input_img = cv2.imread(image_path)

    # Convert to grayscale if RGB
    if input_img.ndim == 3 and input_img.shape[-1] == 3:
        img = cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)
    elif input_img.ndim == 2:
        img = input_img
    else:
        raise Exception("The module works only with grayscale and RGB images!")

    # Create a DataFrame to store features
    temp_df = pd.DataFrame()

    # Feature extraction code (same as in the training phase)
    # Add your feature extraction code here
    # Add pixel values to the data frame
    pixel_values = img.reshape(-1)
    temp_df['Pixel_Value'] = pixel_values  # Pixel value itself as a feature

    # Generate Gabor features
    num = 1  # To count numbers up in order to give Gabor features a label in the data frame
    kernels = []
    for theta in range(2):  # Define number of thetas
        theta = theta / 4. * np.pi
        for sigma in (1, 3):  # Sigma with 1 and 3
            for lamda in np.arange(0, np.pi, np.pi / 4):  # Range of wavelengths
                for gamma in (0.05, 0.5):  # Gamma values of 0.05 and 0.5
                    gabor_label = 'Gabor' + str(num)  # Label Gabor columns as Gabor1, Gabor2, etc.
                    kernel = cv2.getGaborKernel((9, 9), sigma, theta, lamda, gamma, 0, ktype=cv2.CV_32F)
                    kernels.append(kernel)
                    # Now filter the image and add values to a new column
                    fimg = cv2.filter2D(img, cv2.CV_8UC3, kernel)
                    filtered_img = fimg.reshape(-1)
                    temp_df[gabor_label] = filtered_img  # Label columns as Gabor1, Gabor2, etc.
                    print(gabor_label, ': theta=', theta, ': sigma=', sigma, ': lamda=', lamda, ': gamma=', gamma)
                    num += 1  # Increment for gabor column label
      # Add Canny edge feature
    edges = cv2.Canny(img, 100, 200)
    edges1 = edges.reshape(-1)
    temp_df['Canny Edge'] = edges1

    # Add Roberts edge feature
    edge_roberts = roberts(img)
    edge_roberts1 = edge_roberts.reshape(-1)
    temp_df['Roberts'] = edge_roberts1

    # Add Sobel edge feature
    edge_sobel = sobel(img)
    edge_sobel1 = edge_sobel.reshape(-1)
    temp_df['Sobel'] = edge_sobel1

    # Add Scharr edge feature
    edge_scharr = scharr(img)
    edge_scharr1 = edge_scharr.reshape(-1)
    temp_df['Scharr'] = edge_scharr1

    # Add Prewitt edge feature
    edge_prewitt = prewitt(img)
    edge_prewitt1 = edge_prewitt.reshape(-1)
    temp_df['Prewitt'] = edge_prewitt1

    # Add Gaussian filter with sigma=3
    gaussian_img = nd.gaussian_filter(img, sigma=3)
    gaussian_img1 = gaussian_img.reshape(-1)
    temp_df['Gaussian s3'] = gaussian_img1

    # Add Gaussian filter with sigma=7
    gaussian_img2 = nd.gaussian_filter(img, sigma=7)
    gaussian_img3 = gaussian_img2.reshape(-1)
    temp_df['Gaussian s7'] = gaussian_img3

    # Add Median filter with size=3
    median_img = nd.median_filter(img, size=3)
    median_img1 = median_img.reshape(-1)
    temp_df['Median s3'] = median_img1


    # Return the extracted features as a numpy array
    return temp_df


# Define a function to calculate Intersection over Union (IoU)
def calculate_iou(y_true, y_pred):
    intersection = np.logical_and(y_true, y_pred).sum()
    union = np.logical_or(y_true, y_pred).sum()
    iou = intersection / union
    return iou

# Define a function to calculate Dice coefficient
def calculate_dice(y_true, y_pred):
    numerator = 2 * np.logical_and(y_true, y_pred).sum()
    denominator = y_true.sum() + y_pred.sum()
    dice = numerator / denominator
    return dice

"""test the model on the testing images."""

# Define the path to the test tumor images folder
test_tumor_folder_path = "brain_tumor_custom/Tumor"

# Define the path to the folder containing actual masks
actual_mask_folder_path = "brain_tumor_custom/Mask"
actual_mask = cv2.imread("brain_tumor_custom/Mask/TCGA_CS_6667_20011105_11_mask.tif", cv2.IMREAD_GRAYSCALE)

# Define empty lists to store IOU and Dice scores
iou_scores = []
dice_scores = []

# Iterate over all images in the test tumor folder
for image_file in os.listdir(test_tumor_folder_path):
    if image_file in test_names:
        if image_file.endswith('.tif'):  # Check if the file is an image
            # Construct the full path to the image
            image_path = os.path.join(test_tumor_folder_path, image_file)

            # Extract features from the image
            new_image_features = extract_features(image_path)

            # Remove the 'Image_Name' column if present
            if 'Image_Name' in new_image_features.columns:
                new_image_features.drop(columns=['Image_Name'], inplace=True)

            # Make predictions using the trained model
            predicted_mask = RFmodel.predict(new_image_features)
            predicted_mask = predicted_mask.reshape((actual_mask.shape[0], actual_mask.shape[1]))

            # Define the path to the actual mask for the current image
            actual_mask_path = os.path.join(actual_mask_folder_path, image_file.split('.')[0] + "_mask.tif")

            # Read the actual mask for the current image
            actual_mask = cv2.imread(actual_mask_path, cv2.IMREAD_GRAYSCALE)

            # Read the actual image for the current image
            actual_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

            # Calculate IoU and Dice coefficient
            iou = calculate_iou(actual_mask, predicted_mask)
            dice = calculate_dice(actual_mask, predicted_mask)

            # Append IoU and Dice scores to the lists
            iou_scores.append(iou)
            dice_scores.append(dice)
            print(iou,dice)

            # Plot the actual image, actual mask, and predicted mask
            plt.figure(figsize=(15, 5))

            # Plot the actual image
            plt.subplot(1, 3, 1)
            plt.imshow(actual_image, cmap='gray')
            plt.title('Actual Image')
            plt.axis('off')

            # Plot the actual mask
            plt.subplot(1, 3, 2)
            plt.imshow(actual_mask, cmap='gray')
            plt.title('Actual Mask')
            plt.axis('off')

            # Plot the predicted mask
            plt.subplot(1, 3, 3)
            plt.imshow(predicted_mask, cmap='gray')
            plt.title('Predicted Mask')
            plt.axis('off')

            plt.show()

# Calculate average IoU and Dice coefficient
average_iou = np.mean(iou_scores)
average_dice = np.mean(dice_scores)

print("Average Intersection over Union (IoU):", average_iou)
print("Average Dice Coefficient:", average_dice)

"""**Conclusion:**
we are still working on the first pase Random forest model , the model need more refinement and improvemnets we are planning to apply Morphological processing dilation , adjust contrast, add more filters like filters that able to cpture edges or boundaries and load images as RGB


and them move to the second phase that relies on deep learning model unet.

### first improvemnet:
adding contrast:
"""

dataset_of_images = pd.DataFrame()  # Initialize DataFrame to store image data
for image in sorted(os.listdir(path)):
    if image in train_names:
        print(image)
        temp_df = pd.DataFrame()  # Create a temporary DataFrame for each image
        input = cv2.imread(os.path.join(path, image))  # Use os.path.join to construct file paths

        if input is None:
            print(f"Failed to read image: {image}")
            continue  # Skip processing this image and move to the next one

        # Check all images are gray scale images and 2D
        if input.ndim == 3 and input.shape[-1] == 3:
            img = cv2.cvtColor(input, cv2.COLOR_BGR2GRAY)
        elif input.ndim == 2:
           img = input
        else:
           raise Exception("This model works only with 2D")


        #add contrast:
        plt.subplot(1, 2, 1)
        plt.title("Original")
        plt.imshow(img,cmap="gray")

        brightness = 0
        # Adjusts the contrast by scaling the pixel values by 2.3
        contrast = 2.5
        img = cv2.addWeighted(img, contrast, np.zeros(img.shape, img.dtype), 0, brightness)

        #Plot the contrast image
        plt.subplot(1, 2, 2)
        plt.title("Imag with 2.5 contrast")
        plt.imshow(img,cmap="gray")
        plt.show()

        # ADD DATA TO THE DATAFRAME

        # Add pixel values to the data frame
        pixel_values = img.reshape(-1)
        temp_df['Pixel_Value'] = pixel_values  # Pixel value itself as a feature
        temp_df['Image_Name'] = image  # Capture image name as we read multiple images

        # Generate Gabor features
        num = 1  # To count numbers up in order to give Gabor features a label in the data frame
        kernels = []
        for theta in range(2):  # Define number of thetas
            theta = theta / 4. * np.pi
            for sigma in (1, 3):  # Sigma with 1 and 3
                for lamda in np.arange(0, np.pi, np.pi / 4):  # Range of wavelengths
                    for gamma in (0.05, 0.5):  # Gamma values of 0.05 and 0.5
                        gabor_label = 'Gabor' + str(num)  # Label Gabor columns as Gabor1, Gabor2, etc.
                        kernel = cv2.getGaborKernel((9, 9), sigma, theta, lamda, gamma, 0, ktype=cv2.CV_32F)
                        kernels.append(kernel)
                        # Now filter the image and add values to a new column
                        fimg = cv2.filter2D(img, cv2.CV_8UC3, kernel)
                        filtered_img = fimg.reshape(-1)
                        temp_df[gabor_label] = filtered_img  # Label columns as Gabor1, Gabor2, etc.
                        print(gabor_label, ': theta=', theta, ': sigma=', sigma, ': lamda=', lamda, ': gamma=', gamma)
                        num += 1  # Increment for gabor column label



         # Add Canny edge feature
        edges = cv2.Canny(img, 100, 200)
        edges1 = edges.reshape(-1)
        temp_df['Canny Edge'] = edges1

        # Add Roberts edge feature
        edge_roberts = roberts(img)
        edge_roberts1 = edge_roberts.reshape(-1)
        temp_df['Roberts'] = edge_roberts1

        # Add Sobel edge feature
        edge_sobel = sobel(img)
        edge_sobel1 = edge_sobel.reshape(-1)
        temp_df['Sobel'] = edge_sobel1

        # Add Scharr edge feature
        edge_scharr = scharr(img)
        edge_scharr1 = edge_scharr.reshape(-1)
        temp_df['Scharr'] = edge_scharr1

        # Add Prewitt edge feature
        edge_prewitt = prewitt(img)
        edge_prewitt1 = edge_prewitt.reshape(-1)
        temp_df['Prewitt'] = edge_prewitt1

        # Add Gaussian filter with sigma=3
        gaussian_img = nd.gaussian_filter(img, sigma=3)
        gaussian_img1 = gaussian_img.reshape(-1)
        temp_df['Gaussian s3'] = gaussian_img1

        # Add Gaussian filter with sigma=7
        gaussian_img2 = nd.gaussian_filter(img, sigma=7)
        gaussian_img3 = gaussian_img2.reshape(-1)
        temp_df['Gaussian s7'] = gaussian_img3

        # Add Median filter with size=3
        median_img = nd.median_filter(img, size=3)
        median_img1 = median_img.reshape(-1)
        temp_df['Median s3'] = median_img1



        # Update dataframe for images to include details for each image in the loop
        dataset_of_images = pd.concat([dataset_of_images, temp_df], axis=0)

#concatinate both datasets.
entire_dataset = pd.concat([dataset_of_images, mask_dataset], axis=1)

# Assuming 'Image_Name' and 'Mask_Name' are columns in your DataFrame 'entire_dataset'

# Extract the common part of the names (without the '_mask' suffix)
entire_dataset['Mask_Name'] = entire_dataset['Mask_Name'].str.replace('_mask', '')

# Check if the common parts of the names are equal
matches = entire_dataset['Image_Name'] == entire_dataset['Mask_Name']

# Check if all matches are True
if matches.all():
    print("All images match their corresponding masks.")
else:
    print("Some images do not match their corresponding masks.")

"""splitting the data into train and validation"""

X = entire_dataset.drop(labels = ["Image_Name", "Mask_Name", "Label_Value"], axis=1)
Y = entire_dataset["Label_Value"].values
print(np.unique(Y))
Y = LabelEncoder().fit_transform(Y)
print(np.unique(Y))
##Split data into train and test
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=20)

"""Modeling"""

RFmodel = RandomForestClassifier(n_estimators = 50, random_state = 42)
## Train the model on training data
RFmodel.fit(X_train, y_train)
prediction_test = RFmodel.predict(X_test)
##Check accuracy on test dataset.
print ("Accuracy = ", metrics.accuracy_score(y_test, prediction_test))

print("Classes in the image are: ", np.unique(Y))
#ROC curve for RF
roc_auc=ROCAUC(RFmodel, classes=[0, 1])  #Create object
roc_auc.fit(X_train, y_train)
roc_auc.score(X_test, y_test)
roc_auc.show()

##Save the trained model as pickle string to disk for future use
model_name = "segmentation"
pickle.dump(RFmodel, open(model_name, 'wb'))

"""test model on testing data"""

# Define a function to extract features from an image
def extract_features(input_img):

    # Convert to grayscale if RGB
    if input_img.ndim == 3 and input_img.shape[-1] == 3:
        img = cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)
    elif input_img.ndim == 2:
        img = input_img
    else:
        raise Exception("The module works only with grayscale and RGB images!")

    # Create a DataFrame to store features
    temp_df = pd.DataFrame()

    # Feature extraction code (same as in the training phase)
    # Add your feature extraction code here
    # Add pixel values to the data frame
    pixel_values = img.reshape(-1)
    temp_df['Pixel_Value'] = pixel_values  # Pixel value itself as a feature

    # Generate Gabor features
    num = 1  # To count numbers up in order to give Gabor features a label in the data frame
    kernels = []
    for theta in range(2):  # Define number of thetas
        theta = theta / 4. * np.pi
        for sigma in (1, 3):  # Sigma with 1 and 3
            for lamda in np.arange(0, np.pi, np.pi / 4):  # Range of wavelengths
                for gamma in (0.05, 0.5):  # Gamma values of 0.05 and 0.5
                    gabor_label = 'Gabor' + str(num)  # Label Gabor columns as Gabor1, Gabor2, etc.
                    kernel = cv2.getGaborKernel((9, 9), sigma, theta, lamda, gamma, 0, ktype=cv2.CV_32F)
                    kernels.append(kernel)
                    # Now filter the image and add values to a new column
                    fimg = cv2.filter2D(img, cv2.CV_8UC3, kernel)
                    filtered_img = fimg.reshape(-1)
                    temp_df[gabor_label] = filtered_img  # Label columns as Gabor1, Gabor2, etc.
                    print(gabor_label, ': theta=', theta, ': sigma=', sigma, ': lamda=', lamda, ': gamma=', gamma)
                    num += 1  # Increment for gabor column label


      # Add Canny edge feature
    edges = cv2.Canny(img, 100, 200)
    edges1 = edges.reshape(-1)
    temp_df['Canny Edge'] = edges1

    # Add Roberts edge feature
    edge_roberts = roberts(img)
    edge_roberts1 = edge_roberts.reshape(-1)
    temp_df['Roberts'] = edge_roberts1

    # Add Sobel edge feature
    edge_sobel = sobel(img)
    edge_sobel1 = edge_sobel.reshape(-1)
    temp_df['Sobel'] = edge_sobel1

    # Add Scharr edge feature
    edge_scharr = scharr(img)
    edge_scharr1 = edge_scharr.reshape(-1)
    temp_df['Scharr'] = edge_scharr1

    # Add Prewitt edge feature
    edge_prewitt = prewitt(img)
    edge_prewitt1 = edge_prewitt.reshape(-1)
    temp_df['Prewitt'] = edge_prewitt1

    # Add Gaussian filter with sigma=3
    gaussian_img = nd.gaussian_filter(img, sigma=3)
    gaussian_img1 = gaussian_img.reshape(-1)
    temp_df['Gaussian s3'] = gaussian_img1

    # Add Gaussian filter with sigma=7
    gaussian_img2 = nd.gaussian_filter(img, sigma=7)
    gaussian_img3 = gaussian_img2.reshape(-1)
    temp_df['Gaussian s7'] = gaussian_img3

    # Add Median filter with size=3
    median_img = nd.median_filter(img, size=3)
    median_img1 = median_img.reshape(-1)
    temp_df['Median s3'] = median_img1


    # Return the extracted features as a numpy array
    return temp_df

# Define the path to the test tumor images folder
test_tumor_folder_path = "brain_tumor_custom/Tumor"

# Define the path to the folder containing actual masks
actual_mask_folder_path = "brain_tumor_custom/Mask"
actual_mask = cv2.imread("brain_tumor_custom/Mask/TCGA_CS_6667_20011105_11_mask.tif", cv2.IMREAD_GRAYSCALE)

# Define empty lists to store IOU and Dice scores
iou_scores = []
dice_scores = []

# Iterate over all images in the test tumor folder
for image_file in os.listdir(test_tumor_folder_path):
    if image_file in test_names:
        if image_file.endswith('.tif'):  # Check if the file is an image
            # Construct the full path to the image
            image_path = os.path.join(test_tumor_folder_path, image_file)
            #add contrast:
            input = cv2.imread(image_path)
            brightness = 0
            # Adjusts the contrast by scaling the pixel values by 2.3
            contrast = 2.5
            img = cv2.addWeighted(input, contrast, np.zeros(input.shape, input.dtype), 0, brightness)

            # Extract features from the image
            new_image_features = extract_features(img)

            # Remove the 'Image_Name' column if present
            if 'Image_Name' in new_image_features.columns:
                new_image_features.drop(columns=['Image_Name'], inplace=True)

            # Make predictions using the trained model
            predicted_mask = RFmodel.predict(new_image_features)
            predicted_mask = predicted_mask.reshape((actual_mask.shape[0], actual_mask.shape[1]))

            # Define the path to the actual mask for the current image
            actual_mask_path = os.path.join(actual_mask_folder_path, image_file.split('.')[0] + "_mask.tif")

            # Read the actual mask for the current image
            actual_mask = cv2.imread(actual_mask_path, cv2.IMREAD_GRAYSCALE)

            # Read the actual image for the current image
            actual_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

            # Calculate IoU and Dice coefficient
            iou = calculate_iou(actual_mask, predicted_mask)
            dice = calculate_dice(actual_mask, predicted_mask)

            # Append IoU and Dice scores to the lists
            iou_scores.append(iou)
            dice_scores.append(dice)
            print(iou,dice)

            # Plot the actual image, actual mask, and predicted mask
            plt.figure(figsize=(15, 5))

            # Plot the actual image
            plt.subplot(1, 3, 1)
            plt.imshow(actual_image, cmap='gray')
            plt.title('Actual Image')
            plt.axis('off')

            # Plot the actual mask
            plt.subplot(1, 3, 2)
            plt.imshow(actual_mask, cmap='gray')
            plt.title('Actual Mask')
            plt.axis('off')

            # Plot the predicted mask
            plt.subplot(1, 3, 3)
            plt.imshow(predicted_mask, cmap='gray')
            plt.title('Predicted Mask')
            plt.axis('off')

            plt.show()

# Calculate average IoU and Dice coefficient
average_iou = np.mean(iou_scores)
average_dice = np.mean(dice_scores)

print("Average Intersection over Union (IoU):", average_iou)
print("Average Dice Coefficient:", average_dice)